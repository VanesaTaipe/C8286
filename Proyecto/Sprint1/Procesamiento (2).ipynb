{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPhE5ut1MrbRw3jYaPmy7XO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanesaTaipe/C8286/blob/main/Procesamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"/content/tweets_sin_entrenamiento.csv\")"
      ],
      "metadata": {
        "id": "LYM-5W0hGH7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ATxJqC4yGZJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "3I8FbkFjIq9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar cuántos tweets hay de cada tipo de sentimiento\n",
        "sentiment_counts = data['sentiment'].value_counts()\n",
        "\n",
        "print(sentiment_counts)"
      ],
      "metadata": {
        "id": "So-PqcqYJD6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limpieza de datos\n",
        "1.Eliminación de stopwords:<BR>\n",
        "Las stopwords son palabras comunes que no aportan un significado significativo al análisis, como \"el\", \"la\", \"de\", \"en\", etc.\n",
        "Al eliminar las stopwords, se reduce el ruido y se enfoca en las palabras más relevantes para el análisis de sentimientos.\n",
        "Esto ayuda a mejorar la eficiencia computacional y la precisión del análisis."
      ],
      "metadata": {
        "id": "clOcSJGiEw_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "data['tweet'] = data['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
      ],
      "metadata": {
        "id": "2xyd0pSuEwTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['tweet']"
      ],
      "metadata": {
        "id": "MvROKnAcFqt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Manejo de emojis: Los emojis son caracteres especiales que pueden aparecer en los tweets y pueden ser relevantes para el análisis de sentimientos. Sin embargo, también pueden ser considerados ruido si no se manejan adecuadamente."
      ],
      "metadata": {
        "id": "w25_iVwzOEBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "def remove_emojis(text):\n",
        "    return emoji.replace_emoji(text, '')\n",
        "\n",
        "# Aplicar la función de eliminación de emojis a la columna 'tweet'\n",
        "data['tweet_sin_emojis'] = data['tweet'].apply(remove_emojis)"
      ],
      "metadata": {
        "id": "05qxyAI9ODeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tokenización: La tokenización es el proceso de dividir el texto en unidades más pequeñas llamadas tokens, que generalmente son palabras individuales. Este paso es necesario para realizar operaciones posteriores, como la lematización."
      ],
      "metadata": {
        "id": "PlE2h1DqQEI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "data['tweet_tokens'] = data['tweet_sin_emojis'].apply(tokenize)"
      ],
      "metadata": {
        "id": "FGNieyqFQHsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Lematización: La lematización es el proceso de reducir las palabras a su forma base o lema. Esto ayuda a agrupar palabras con diferentes formas gramaticales (por ejemplo, \"correr\", \"corriendo\", \"corrí\") en una sola forma base, lo que puede mejorar la precisión del análisis."
      ],
      "metadata": {
        "id": "4Acj9XKRQJ4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def lematize(tokens):\n",
        "    lemmas = [stemmer.stem(token) for token in tokens]\n",
        "    return lemmas\n",
        "\n",
        "data['tweet_lemmas'] = data['tweet_tokens'].apply(lematize)"
      ],
      "metadata": {
        "id": "BJp9XJoJQNnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "0TNX2iFrOS8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Estructurar los datos en un formato adecuado:"
      ],
      "metadata": {
        "id": "C4C9UFUXG7lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de realizar todos los pasos de preprocesamiento, es importante estructurar los datos en un formato adecuado para el análisis posterior. Esto puede implicar crear una nueva columna que combine el texto procesado y el sentimiento asociado, o cualquier otra transformación necesaria para facilitar el análisis."
      ],
      "metadata": {
        "id": "bjXCER_bQXOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['texto_procesado'] = data['tweet_lemmas'].apply(lambda x: ' '.join(x))\n",
        "data['texto_sentimiento'] = data['texto_procesado'] + ' ' + data['sentiment']"
      ],
      "metadata": {
        "id": "19la7R7iQYSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "fQMO2V07QrkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso la columna **likes** y **source** son datos que ayudarian bastante a analizar el sentimiento. Este caso no tienen valor por ello debemos eliminar.\n",
        "\n"
      ],
      "metadata": {
        "id": "LvQFB2DOHcZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Contar cuántos tweets tienen al menos un like\n",
        "num_liked_tweets = (data['likes'] > 0).sum()\n",
        "\n",
        "print(f'Hay {num_liked_tweets} tweets que tienen al menos un like.')\n"
      ],
      "metadata": {
        "id": "Y2xnfQuMHaHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solo 53 tweets tiene al menos un like. En ello no aportaria nada al analisis."
      ],
      "metadata": {
        "id": "xyjHpJUqIIXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conservar solo las columnas necesarias\n",
        "data_procesada = data[['user_id', 'texto_sentimiento','created_at','sentiment']]"
      ],
      "metadata": {
        "id": "vu747CdmRBW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_procesada"
      ],
      "metadata": {
        "id": "kTp33QMURWvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos los datos duplicados tanto del user_id como tweet."
      ],
      "metadata": {
        "id": "bd0B-XMTHOvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_procesada = data_procesada .drop_duplicates(subset=['user_id', 'texto_sentimiento'])"
      ],
      "metadata": {
        "id": "_j9cxAm-1UhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_procesada"
      ],
      "metadata": {
        "id": "ilNu0Z_aRjiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar cuántos tweets hay de cada tipo de sentimiento\n",
        "sentiment_counts = data_procesada['sentiment'].value_counts()\n",
        "\n",
        "print(sentiment_counts)"
      ],
      "metadata": {
        "id": "6UDB_69fR5KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar los datos preprocesados en un archivo CSV\n",
        "data_procesada.to_csv('Data_preprocesados.csv', index=False)"
      ],
      "metadata": {
        "id": "wx7sMsDsSEDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}